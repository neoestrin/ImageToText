# -*- coding: utf-8 -*-
"""Image to Text (Optical Character Recognition).ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1WLYoGa1QxScA8dYtpBapBqDkNiNJIJ5r

#Installing required libraries:
"""

!sudo apt install tesseract-ocr
!pip install pytesseract

"""# Importing relevant libraries and viewing the image that needs to be worked upon:"""

import pytesseract
import cv2
from google.colab.patches import cv2_imshow       # Although cv2.imshow() should work, it crashes in google colab. Hence, we import this library

"""#Uploading images that need to be scanned:"""

from google.colab import files
files.upload()

"""# Writing a function which takes image as an input and returns the extracted text"""

def extract(image):
    img = cv2.imread(image)
    cv2_imshow(img)
    text = pytesseract.image_to_string(img)
    print(text)

"""# Extracting text from the image:"""

extract("star wars.jpg")

"""Couldn't capture Star Wars (Mostly for the font style), no errors in anything else.

# Trying the same on other image:

Now let us try it on reading something like a restaurant bill:
"""

extract("2.JPG")

"""Now here we can see that it has got few things wrong as opposed to the case above.

We can see that the Terminal ID is captured wrong, the four-digit number on the end of the credit card is wrongly read as "O" instead of "0". It even added a space between 4 and 1.
Furthermore couldn't capture the tip as well.

Now we can assume that these errors have occurred because of the complexities in the image, such as the folded bill, font, etc.

Let us try this on something cruder like a *kaccha* bill:
"""

extract("5.jpg")

"""Now we can see that with a handwritten bill it goofed up even further. This is where we find a limitation of a pre-trained model like Pytesseract. For further accuracy, we need to train the model with images of our own."""